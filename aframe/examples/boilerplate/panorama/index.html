<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>360&deg; Image</title>
  <meta name="description" content="360&deg; Image - A-Frame">
  <script src="../../../dist/aframe-master.js"></script>
  <script src="https://cdn.jsdelivr.net/gh/c-frame/aframe-extras@7.2.0/dist/aframe-extras.min.js"></script>
  <script src="https://aka.ms/csspeech/jsbrowserpackageraw"></script>


  <style>
    #chatUI {
    width: 300px;
    height: 35px;
    position: absolute;
    z-index: 10;
    background-color: whitesmoke;
    overflow: auto;
    left: 50%; /* Set the left position to 50% */
    transform: translateX(-50%); /* Translate it back by -50% of its own width */
    align-items: center; /* Center items horizontally */
    justify-content: center; /* Center items vertically */
    display: flex;
    }
  </style>



</head>
<body>
  <div id="chatUI">
    <input type="text">
    <button>
      SEND
    </button>
    <div id="messages">
    </div>
  </div>


  <a-scene>
    <a-sky src="louvre.jpg" rotation="0 0 0"></a-sky>

    <a-assets>
      <a-asset-item id="constantine" src="../../assets/models/constantine_anim.glb"></a-asset-item>
    </a-assets>


    <a-gltf-model id="animatedModel" src="#constantine" scale="2 2 2" position="-2 0 0" rotation="0 0 0" animation-mixer="clip: idle1;"></a-gltf-model>
    <a-entity position="0 .6 4">
      <a-camera>
        <a-entity id="mycursor" cursor="fuse: true; fuseTimeout: 500; max-distance: 30;"
        position="0 0 -1"
        geometry="primitive: sphere; radius: 0.01"
        material="color: blue; shader: flat">
      </a-entity>
      
      </a-camera>
    </a-entity>


    <a-text id="recognizedText" value="Recognized Text Placeholder" position="0 2 -3"></a-text>

    <a-text id="response" value="AI Response Placeholder" position="0 3 -3"></a-text>


    <!-- "button" -->

    <a-entity
    id="myButton"
    geometry="primitive: plane; width: 1.25; height: 0.5"
    material="color: red; shader: flat"
    position="0 1 -3"
    class="raycastable menu-button">
    <a-text value="Record" align="center" color="white"></a-text>
    </a-entity>


  </a-scene>

  <script>
    //import { sendTextToConvAI } from '../../../convaiIntegration.js';

    var SpeechSDK;
    var isRecording = false;
///////////////////////////////ws
    const wsProtocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
    const wsURL = `${wsProtocol}//${window.location.host}`;
    const ws = new WebSocket(wsURL);

    ws.onopen = function() {
      console.log('Connected to the server');
    };

    ws.onmessage = function(event) {
    try {
        const data = JSON.parse(event.data);
        console.log('Message from server:', data);
        var responseText = document.querySelector('#response');
        responseText.setAttribute('value', data.message || 'No response');
    } catch (error) {
        console.error('Error parsing server message:', error);
    }
};

    ws.onerror = function(error) {
      console.error('WebSocket error:', error);
    };

    ws.onclose = function() {
      console.log('WebSocket connection closed');
    };

    // Sending user input to server via WebSocket
    document.querySelector('#chatUI button').addEventListener('click', function () {
      var text = document.querySelector('#chatUI input').value;
      if (text) {
        ws.send(text); // Send text to server
        document.querySelector('#chatUI input').value = ''; // Clear the input field
      }
    });

////////////////////////
    document.addEventListener('DOMContentLoaded', async function () {
      try {
        // Request microphone permission
        await navigator.mediaDevices.getUserMedia({ audio: true });
        // Fetch the configuration from the server
        const configResponse = await fetch('/api/config');
        const config = await configResponse.json();
        var subscriptionKey = config.SPEECH_KEY; // Use the key from the server

        var serviceRegion = 'westus'; // Replace with your service region

        var recognizeButton = document.querySelector('#myButton');
        var recognizedText = document.querySelector('#recognizedText');

        var sendButton = document.querySelector('#chatUI button');
        var inputField = document.querySelector('#chatUI input');
        var messagesDiv = document.querySelector('#messages');


        sendButton.addEventListener('click', function () {
          var text = inputField.value;
          if (text) {
            console.log("Sending ... " + text);
            fetch('/api/inworld-interaction', {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({ text: text })
            })
            .then(response => {
              if (!response.ok) { throw new Error('Network response was not ok ' + response.statusText); }
              return response.json();
            })
            .then(data => {
              console.log("getting response... " + data);
              var responseText = document.querySelector('#response');
              responseText.setAttribute('value', data.messages.join(' ')); // Update A-Frame text
            })
            .catch((error) => {
              console.error('Error:', error);
            });
            inputField.value = ''; // Clear the input field
          }
        });



        if (!!window.SpeechSDK) {
          SpeechSDK = window.SpeechSDK;
          recognizeButton.disabled = false;

          recognizeButton.addEventListener('click', function () {
            if (!isRecording) {
              isRecording = true;
              recognizeButton.setAttribute('material', 'color', 'green');

              // Configure the speech SDK with the fetched subscription key
              var speechConfig = SpeechSDK.SpeechConfig.fromSubscription(subscriptionKey, serviceRegion);
              speechConfig.speechRecognitionLanguage = "en-US";
              var audioConfig = SpeechSDK.AudioConfig.fromDefaultMicrophoneInput();
              var recognizer = new SpeechSDK.SpeechRecognizer(speechConfig, audioConfig);

              recognizer.recognizeOnceAsync(
                function (result) {
                  recognizedText.setAttribute('value', result.text); // Update the recognized text in the A-Frame scene
                  inputField.value = result.text;
                  isRecording = false;
                  recognizeButton.setAttribute('material', 'color', 'red'); // Change button color back to red when recording stops
                  recognizer.close();
                },
                function (err) {
                  console.error('Speech recognition error:', err);
                  isRecording = false;
                  recognizeButton.setAttribute('material', 'color', 'red'); // Change button color back to red if an error occurs
                  recognizer.close();
                }
              );
            }
          });
        } else {
          console.error('Speech SDK not found!');
        }
      } catch (error) {
        console.error('Error fetching configuration:', error);
      }


      // Animation selection logic
      document.body.addEventListener('keydown', function(event) {
        switch(event.key) {
          case '1':
            model.setAttribute('animation-mixer', {clip: animations[0]});
            break;
          case '2':
            model.setAttribute('animation-mixer', {clip: animations[1]});
            break;
          case '3':
            model.setAttribute('animation-mixer', {clip: animations[2]});
            break;
          case '4':
            model.setAttribute('animation-mixer', {clip: animations[3]});
            break;
        }
      });
    });
  </script>
</body>
</html>
